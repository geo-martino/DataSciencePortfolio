{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Work in Progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending Top-N movies - Part 2: Testing recommendation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 1 of this project, we looked at the MovieLens data set and implemented algorithms to recommend movies based off of this. We took a brief look at some of these algorithms parameters and differences in runtime. In this part of the project, we will use various metrics to test the accuracy and validity of the recommended movies using a train-test-validation split of the reduced data set.\n",
    "\n",
    "To do this we'll use three new classes: SplitData, Metrics, and Tester which split the ratings pivot data frame, run metrics on the recommendations, and run tests over multiple users respectively. More documentation for these classes can be found in the MovieLensData.py and Tester.py files, with further information on the algorithms in the Algorithms.py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "- Creating the ratings pivot data frame\n",
    "- Splitting the data for testing\n",
    "- Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing the required packages and building the ratings pivot data frame from a reduced set of data. As discussed in the part 1, we're sampling users with rating counts between 200-6000 and limiting movies to those with more than 100 ratings to avoid biases from outliers and to work within the constraints of computing power available. However, as the tests are very computationally intensive, I will initially be reducing this further by taking a random sample of 10% of the reduced userIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from time import perf_counter\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "import importlib\n",
    "import random\n",
    "import MovieLensData\n",
    "import Algorithms\n",
    "import Tester\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\u001b[92m Done \u001b[0m\n",
      "Building movies/ratings pivot df...\u001b[92m Done \u001b[0m\n",
      "\u001b[94m3528 / 283228 users retained (1.25%)\u001b[0m\n",
      "\u001b[94m10500 / 58098 movies retained (18.07%)\u001b[0m\n",
      "\u001b[94m1679766 / 27753444 ratings retained (6.05%)\u001b[0m\n",
      "\u001b[94m95.47% sparsity\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ml = MovieLensData.MovieLensData()\n",
    "userIDs = ml.filterIDs('userId', minRatings=200, maxRatings=6000)\n",
    "movieIDs = ml.filterIDs('movieId', minRatings=100)\n",
    "userIDs = random.sample(userIDs, int(0.1 * len(userIDs)))\n",
    "ml.reduce(userIDs, 'userId', 'ratings')\n",
    "ml.reduce(movieIDs, 'movieId', 'movies')\n",
    "\n",
    "ratingsData = ml.buildPivot(printStats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SplitData class splits up the ratings pivot data frame into a trainSet and testSet_full. testSet_full is then split in two ways: one into a a test-validation split where every user in testSet_full has a percentage or number of ratings split off into the validation set, and one that takes away just one rating from each user for leave-one-out cross validation (LOO-CV). The size of testSet_full and validation sets are governed by the testSize and validationSize parameters respectively. As the data is relatively large, we afford to keep more users in the train set, so 20% splits will be used for both the testSize and validationSize parameters.\n",
    "\n",
    "The ratings in the test set are used to generate recommendations, with the two validation sets used to check the quality of recommendations against various metrics. We can ensure the same splits occur each time via the randomState parameter for consistency in results reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train/test/validation split by row...\u001b[92m Done \u001b[0m\n",
      "Building LeaveOneOut-CrossValidation data...\u001b[92m Done \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train, test, validation, LOO_test, LOO_dropped = MovieLensData.SplitData(ratingsData).buildAll(testSize=0.2, \n",
    "                                                                             validationSize=0.2, randomState=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the previous part, we can easily build each model by calling the buildModel method in the Algorithm class. This time, we initialise the method by passing the train and test set data so the program knows which set to build the model from, and which to use to look up ratings for testing. We will also need to call the buildMatrix method to generate the sparse matrix for building the KNN models.\n",
    "\n",
    "However, this time we will not need to generate a similarity matrix for the users. As these models are built off of the train set and we will not be testing any f the userIDs in this set, we do not need to build a user similarity matrix for the CF algorithm and can simply pass 'None' as the model parameter when testing this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising object...\u001b[92m Done \u001b[0m\n",
      "Building sparse matrix...\u001b[92m Done \u001b[0m\n",
      "\u001b[1m\n",
      "Building CF model\u001b[0m\n",
      "Correlating ratings for all movies...\u001b[92m Done \u001b[0m\n",
      "Correlating genres for all movies...\u001b[92m Done \u001b[0m\n",
      "Correlating years for all movies...\u001b[92m Done \u001b[0m\n",
      "Generating combined correlation...\u001b[92m Done \u001b[0m\n",
      "\u001b[92mDone. Time: 15.203528900000002s\u001b[0m\n",
      "\u001b[1m\n",
      "Building KNN model\u001b[0m\n",
      "\u001b[92mDone. Time: 0.022894700000001933s\u001b[0m\n",
      "\u001b[1m\n",
      "Building KNN model\u001b[0m\n",
      "\u001b[92mDone. Time: 0.0064758999999980915s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "algo = Algorithms.Algorithms(ml, train, test)\n",
    "ratingsSparse = algo.buildMatrix()\n",
    "printStatus = True\n",
    "\n",
    "CF_itemModel = algo.buildModel(modelType='CF', matrix='item', printStatus=printStatus)\n",
    "KNN_itemModel = algo.buildModel(modelType='KNN', matrix=ratingsSparse.transpose(), printStatus=printStatus)\n",
    "KNN_userModel = algo.buildModel(modelType='KNN', matrix=ratingsSparse, printStatus=printStatus)\n",
    "#SVD_model = algo.buildModel(modelType='SVD', printStatus=printStatus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Demonstration and Metrics\n",
    "\n",
    "- Adding algorithms for testing\n",
    "- Running basic and parameter tests\n",
    "- MAE, RMSE, Coverage, Diversity, Novelty, Hit Rates (Validation, LOO-CV, Cumulative, Mean Reciprocal, Actual Rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the Tester class\n",
    "\n",
    "The Metrics class contains the various metrics we'll be using the test the quality of our results. This takes the validation and LOO-CV sets to check the results against, a filename for the csv that stores the results, as well as various parameters for testing (discussed below).\n",
    "\n",
    "This object is then passed to the Tester class to create our test object. This object has two primary methods for testing, runBasicTest and runParameterTest, as well as two methods for adding and removin algorithms. All we need to do to set up tests is to instantiate the tester object, and pass the various algorithms' names, method to call, model and all other parameters to control for this test. The parameters we control will be discussed in greater detail when discussing results later in this notebook.\n",
    "\n",
    "Here we'll also add a random control algorithm which simply generates random similarity scores and random rating precitions for every user. The randomRatings parameter of this method determines whether or not the rating predictions are a random number between 0-5 independent of the similarity scores, or if the rating predictions are a multiple of the randomly generated similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML_MetricsData.csv already exists. Update this file (u) or overwrite (o)? u\n",
      "Added Item-Based CF\n",
      "Added User-Based CF\n",
      "Added Item-Based KNN\n",
      "Added User-Based KNN\n",
      "Added Random Control\n"
     ]
    }
   ],
   "source": [
    "filename = 'ML_MetricsData_sample'\n",
    "evaluator = Tester.Metrics(validation, LOO_dropped, topN=10, moviesPerPage=5, thresholdRating=3.0, csvName=filename)\n",
    "tester = Tester.Tester(evaluator)\n",
    "\n",
    "neighbours = 100\n",
    "sample = 100\n",
    "thresh = 2.0\n",
    "\n",
    "tester.addAlgorithm('Item-Based CF', algo.itemBased, model=CF_itemModel, modelType='CF', neighbours=neighbours,\n",
    "                    sample=sample, threshold=thresh, predict='calc')\n",
    "tester.addAlgorithm('User-Based CF', algo.userBased, model=None, modelType='CF', neighbours=neighbours,\n",
    "                    sample=sample, threshold=thresh, predict='calc')\n",
    "tester.addAlgorithm('Item-Based KNN', algo.itemBased, model=KNN_itemModel, modelType='KNN', neighbours=neighbours,\n",
    "                    sample=sample, threshold=thresh, predict='calc')\n",
    "tester.addAlgorithm('User-Based KNN', algo.userBased, model=KNN_userModel, modelType='KNN', neighbours=neighbours,\n",
    "                    sample=sample, threshold=thresh, predict='calc')\n",
    "#tester.addAlgorithm('SVD', algo.SVD, model=SVD_model, sample=sample, pred='calc')\n",
    "tester.addAlgorithm('Random Control', algo.random, randomRatings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ML_MetricsData'\n",
    "evaluator = Tester.Metrics(validation, LOO_dropped, topN=30, moviesPerPage=5, thresholdRating=3.0, csvName=filename)\n",
    "tester = Tester.Tester(evaluator)\n",
    "\n",
    "neighbours = 100\n",
    "sample = 100\n",
    "thresh = 2.0\n",
    "\n",
    "tester.addAlgorithm('Item-Based CF', algo.itemBased, model=CF_itemModel, modelType='CF', neighbours=neighbours,\n",
    "                    sample=sample, threshold=thresh, predict='calc')\n",
    "tester.addAlgorithm('Item-Based KNN', algo.itemBased, model=KNN_itemModel, modelType='KNN', neighbours=neighbours,\n",
    "                    sample=sample, threshold=thresh, predict='calc')\n",
    "tester.addAlgorithm('User-Based CF', algo.userBased, model=None, modelType='CF', neighbours=neighbours,\n",
    "                    sample=sample, threshold=thresh, predict='calc')\n",
    "tester.addAlgorithm('User-Based KNN', algo.userBased, model=KNN_userModel, modelType='KNN', neighbours=neighbours,\n",
    "                    sample=sample, threshold=thresh, predict='calc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = 'sample'\n",
    "pRange = np.arange(150, 2050, 50)\n",
    "\n",
    "#tester.runParameterTest(test, testAlgo='Item-Based KNN', param=parameter, pRange=pRange, printResults=False)\n",
    "tester.runParameterTest(test, testAlgo='User-Based CF', param=parameter, pRange=pRange, printResults=False)\n",
    "tester.runParameterTest(test, testAlgo='User-Based KNN', param=parameter, pRange=pRange, printResults=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = 'neighbours'\n",
    "pRange = np.arange(150, len(train.columns), 50)\n",
    "\n",
    "tester.runParameterTest(test, testAlgo='Item-Based CF', param=parameter, pRange=pRange, printResults=False)\n",
    "\n",
    "parameter = 'neighbours'\n",
    "pRange = np.arange(200, len(train.index), 200)\n",
    "\n",
    "tester.runParameterTest(test, testAlgo='User-Based CF', param=parameter, pRange=pRange, printResults=False)\n",
    "tester.runParameterTest(test, testAlgo='User-Based KNN', param=parameter, pRange=pRange, printResults=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the algorithms loaded, we can now run a simple test using the test set. The runBasicTest takes a few key arguements: \n",
    "- testData - the test set\n",
    "- testAlgo - the name of the algorithm from the dictionary of loaded algorithms to test \n",
    "- sampleTest - the number of users from the test to sample\n",
    "- param, pValue - the paramater and its value to modify from the stored parameters within the object\n",
    "\n",
    "Here we run a simply test on the above using the stored algorithms for 10 randomly sample users in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Random Control:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tester.runBasicTest(test, sampleTest=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LeaveOneOut cross validation metric uses a different set of ratings per user and is therefore needs to be identified when initialising tests. We can define this by setting LOOCV to True. This usually defaults to False, testing the results against the validation HitRate metric instead (metric types discussed below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Random Control:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tester.runBasicTest(LOO_test, LOOCV=True, sampleTest=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runParameterTest method allows us to iterate through a range of values for a given parameter. The parameter is passed to the runBasicTest to run tests across the users present in the test set. This allows us to see the effect of changing parameters within the methods, with the aim of fine-tuning the algorithms. The parameters for this function are much the same as the runBasicTest method, with pValue now replaced with pRange as the range of parameters to test.\n",
    "\n",
    "Here we run a basic demonstration on the 'pred' parameter which changes the rating prediction algorithm (discussed in greater in the results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parameter Testing:   0%|          | 0/4 [00:00<?, ?Parameter/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Random Control:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Random Control:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Random Control:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based CF:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Item-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing User-Based KNN:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Random Control:   0%|          | 0/10 [00:00<?, ? Users/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameter = 'predict'\n",
    "pRange = ['rand', 'calc', 'sims', 'norm_sims']\n",
    "sampleTest = 10\n",
    "\n",
    "tester.runParameterTest(test, param=parameter, pRange=pRange, sampleTest=sampleTest, printResults=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the readCSV method in the evaluator class, we can see the results we have just generated ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Top-N</th>\n",
       "      <th>MoviesPerPage</th>\n",
       "      <th>ThresholdRating</th>\n",
       "      <th>TotalIDs</th>\n",
       "      <th>ParameterTest</th>\n",
       "      <th>ParameterValue</th>\n",
       "      <th>OtherParameters</th>\n",
       "      <th>TotalTime/s</th>\n",
       "      <th>MeanTime/s</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Diversity</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>LOOCV_HR</th>\n",
       "      <th>Validation_HR</th>\n",
       "      <th>Cumulative_HR</th>\n",
       "      <th>MeanReciprocal_HR</th>\n",
       "      <th>ActualRating_HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Item-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>1.093928</td>\n",
       "      <td>0.109393</td>\n",
       "      <td>0.590087</td>\n",
       "      <td>0.646977</td>\n",
       "      <td>0.306962</td>\n",
       "      <td>0.344359</td>\n",
       "      <td>0.076681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.175</td>\n",
       "      <td>{2.0: 0.000819672131147541, 3.0: 0.00880455407...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>13.605833</td>\n",
       "      <td>1.360583</td>\n",
       "      <td>0.349836</td>\n",
       "      <td>0.391245</td>\n",
       "      <td>0.221848</td>\n",
       "      <td>0.438315</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.120</td>\n",
       "      <td>{3.5: 0.0029213955443463642, 4.0: 0.0075286138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Item-Based KNN</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>60.645003</td>\n",
       "      <td>6.064500</td>\n",
       "      <td>0.677091</td>\n",
       "      <td>0.679859</td>\n",
       "      <td>0.111914</td>\n",
       "      <td>0.179893</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.075</td>\n",
       "      <td>{3.0: 0.0032903643050143315, 4.0: 0.0010526315...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User-Based KNN</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>6.682255</td>\n",
       "      <td>0.668226</td>\n",
       "      <td>0.753723</td>\n",
       "      <td>0.803360</td>\n",
       "      <td>0.122867</td>\n",
       "      <td>0.454609</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.225</td>\n",
       "      <td>{1.5: 0.0006134969325153375, 2.0: 0.0021276595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Control</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'randomRatings': True}</td>\n",
       "      <td>0.162845</td>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.543995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Item-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>1.104494</td>\n",
       "      <td>0.110449</td>\n",
       "      <td>0.564364</td>\n",
       "      <td>0.671683</td>\n",
       "      <td>0.280952</td>\n",
       "      <td>0.343810</td>\n",
       "      <td>0.071127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.170</td>\n",
       "      <td>{2.0: 0.002173913043478261, 3.0: 0.00653517759...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>User-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>13.751851</td>\n",
       "      <td>1.375185</td>\n",
       "      <td>0.365606</td>\n",
       "      <td>0.399532</td>\n",
       "      <td>0.216019</td>\n",
       "      <td>0.385336</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.120</td>\n",
       "      <td>{3.0: 0.002000788488074118, 3.5: 0.00112359550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Item-Based KNN</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>63.217344</td>\n",
       "      <td>6.321734</td>\n",
       "      <td>0.404854</td>\n",
       "      <td>0.404854</td>\n",
       "      <td>0.147590</td>\n",
       "      <td>0.141935</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.070</td>\n",
       "      <td>{3.0: 0.00196078431372549, 4.0: 0.004290932799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>User-Based KNN</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>6.825581</td>\n",
       "      <td>0.682558</td>\n",
       "      <td>1.038975</td>\n",
       "      <td>1.085616</td>\n",
       "      <td>0.150381</td>\n",
       "      <td>0.355712</td>\n",
       "      <td>0.007172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.175</td>\n",
       "      <td>{1.0: 0.0011627906976744186, 1.5: 0.0029171766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Control</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'randomRatings': True}</td>\n",
       "      <td>0.159490</td>\n",
       "      <td>0.015949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.490019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Item-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>rand</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>1.225513</td>\n",
       "      <td>0.122551</td>\n",
       "      <td>1.851563</td>\n",
       "      <td>2.132115</td>\n",
       "      <td>0.301229</td>\n",
       "      <td>0.355657</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.190</td>\n",
       "      <td>{1.0: 0.004166666666666667, 2.5: 0.00161290322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>User-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>rand</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>13.655486</td>\n",
       "      <td>1.365549</td>\n",
       "      <td>0.840567</td>\n",
       "      <td>0.908513</td>\n",
       "      <td>0.237981</td>\n",
       "      <td>0.368817</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.100</td>\n",
       "      <td>{3.0: 0.0017543859649122805, 3.5: 0.0037543859...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Item-Based KNN</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>rand</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>62.293561</td>\n",
       "      <td>6.229356</td>\n",
       "      <td>1.581315</td>\n",
       "      <td>1.609300</td>\n",
       "      <td>0.143343</td>\n",
       "      <td>0.153480</td>\n",
       "      <td>0.007868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.080</td>\n",
       "      <td>{2.0: 0.0027777777777777775, 3.5: 0.0038712686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>User-Based KNN</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>rand</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>6.811256</td>\n",
       "      <td>0.681126</td>\n",
       "      <td>1.369214</td>\n",
       "      <td>1.432026</td>\n",
       "      <td>0.142790</td>\n",
       "      <td>0.400323</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.160</td>\n",
       "      <td>{1.0: 0.0014705882352941176, 2.5: 0.0007462686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Item-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>calc</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>1.092454</td>\n",
       "      <td>0.109245</td>\n",
       "      <td>0.605490</td>\n",
       "      <td>0.760722</td>\n",
       "      <td>0.314838</td>\n",
       "      <td>0.345629</td>\n",
       "      <td>0.075653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.180</td>\n",
       "      <td>{2.0: 0.0007518796992481202, 2.5: 0.0023809523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>User-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>calc</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>13.710756</td>\n",
       "      <td>1.371076</td>\n",
       "      <td>0.598623</td>\n",
       "      <td>0.625537</td>\n",
       "      <td>0.217667</td>\n",
       "      <td>0.463848</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.165</td>\n",
       "      <td>{2.5: 0.0013157894736842105, 3.0: 0.0023529411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Item-Based KNN</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>calc</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>62.272036</td>\n",
       "      <td>6.227204</td>\n",
       "      <td>0.176121</td>\n",
       "      <td>0.176121</td>\n",
       "      <td>0.136952</td>\n",
       "      <td>0.167021</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.040</td>\n",
       "      <td>{2.5: 0.002173913043478261, 3.5: 0.00227272727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>User-Based KNN</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>calc</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>6.722564</td>\n",
       "      <td>0.672256</td>\n",
       "      <td>0.680657</td>\n",
       "      <td>0.701166</td>\n",
       "      <td>0.122762</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.170</td>\n",
       "      <td>{2.0: 0.0030638297872340424, 3.0: 0.0006451612...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Item-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>sims</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>1.075191</td>\n",
       "      <td>0.107519</td>\n",
       "      <td>0.696024</td>\n",
       "      <td>0.762412</td>\n",
       "      <td>0.310981</td>\n",
       "      <td>0.347479</td>\n",
       "      <td>0.082290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.200</td>\n",
       "      <td>{3.0: 0.007597063967160636, 3.5: 0.00997442972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>User-Based CF</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>predict</td>\n",
       "      <td>sims</td>\n",
       "      <td>{'neighbours': 100, 'sample': 100, 'threshold'...</td>\n",
       "      <td>13.557014</td>\n",
       "      <td>1.355701</td>\n",
       "      <td>0.740127</td>\n",
       "      <td>0.772587</td>\n",
       "      <td>0.218229</td>\n",
       "      <td>0.429984</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.125</td>\n",
       "      <td>{0.5: 0.0004098360655737705, 2.5: 0.0004098360...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Algorithm  Top-N  MoviesPerPage  ThresholdRating  TotalIDs  \\\n",
       "0    Item-Based CF     10              5                3        10   \n",
       "1    User-Based CF     10              5                3        10   \n",
       "2   Item-Based KNN     10              5                3        10   \n",
       "3   User-Based KNN     10              5                3        10   \n",
       "4   Random Control     10              5                3        10   \n",
       "5    Item-Based CF     10              5                3        10   \n",
       "6    User-Based CF     10              5                3        10   \n",
       "7   Item-Based KNN     10              5                3        10   \n",
       "8   User-Based KNN     10              5                3        10   \n",
       "9   Random Control     10              5                3        10   \n",
       "10   Item-Based CF     10              5                3        10   \n",
       "11   User-Based CF     10              5                3        10   \n",
       "12  Item-Based KNN     10              5                3        10   \n",
       "13  User-Based KNN     10              5                3        10   \n",
       "14   Item-Based CF     10              5                3        10   \n",
       "15   User-Based CF     10              5                3        10   \n",
       "16  Item-Based KNN     10              5                3        10   \n",
       "17  User-Based KNN     10              5                3        10   \n",
       "18   Item-Based CF     10              5                3        10   \n",
       "19   User-Based CF     10              5                3        10   \n",
       "\n",
       "   ParameterTest ParameterValue  \\\n",
       "0            NaN            NaN   \n",
       "1            NaN            NaN   \n",
       "2            NaN            NaN   \n",
       "3            NaN            NaN   \n",
       "4            NaN            NaN   \n",
       "5            NaN            NaN   \n",
       "6            NaN            NaN   \n",
       "7            NaN            NaN   \n",
       "8            NaN            NaN   \n",
       "9            NaN            NaN   \n",
       "10       predict           rand   \n",
       "11       predict           rand   \n",
       "12       predict           rand   \n",
       "13       predict           rand   \n",
       "14       predict           calc   \n",
       "15       predict           calc   \n",
       "16       predict           calc   \n",
       "17       predict           calc   \n",
       "18       predict           sims   \n",
       "19       predict           sims   \n",
       "\n",
       "                                      OtherParameters  TotalTime/s  \\\n",
       "0   {'neighbours': 100, 'sample': 100, 'threshold'...     1.093928   \n",
       "1   {'neighbours': 100, 'sample': 100, 'threshold'...    13.605833   \n",
       "2   {'neighbours': 100, 'sample': 100, 'threshold'...    60.645003   \n",
       "3   {'neighbours': 100, 'sample': 100, 'threshold'...     6.682255   \n",
       "4                             {'randomRatings': True}     0.162845   \n",
       "5   {'neighbours': 100, 'sample': 100, 'threshold'...     1.104494   \n",
       "6   {'neighbours': 100, 'sample': 100, 'threshold'...    13.751851   \n",
       "7   {'neighbours': 100, 'sample': 100, 'threshold'...    63.217344   \n",
       "8   {'neighbours': 100, 'sample': 100, 'threshold'...     6.825581   \n",
       "9                             {'randomRatings': True}     0.159490   \n",
       "10  {'neighbours': 100, 'sample': 100, 'threshold'...     1.225513   \n",
       "11  {'neighbours': 100, 'sample': 100, 'threshold'...    13.655486   \n",
       "12  {'neighbours': 100, 'sample': 100, 'threshold'...    62.293561   \n",
       "13  {'neighbours': 100, 'sample': 100, 'threshold'...     6.811256   \n",
       "14  {'neighbours': 100, 'sample': 100, 'threshold'...     1.092454   \n",
       "15  {'neighbours': 100, 'sample': 100, 'threshold'...    13.710756   \n",
       "16  {'neighbours': 100, 'sample': 100, 'threshold'...    62.272036   \n",
       "17  {'neighbours': 100, 'sample': 100, 'threshold'...     6.722564   \n",
       "18  {'neighbours': 100, 'sample': 100, 'threshold'...     1.075191   \n",
       "19  {'neighbours': 100, 'sample': 100, 'threshold'...    13.557014   \n",
       "\n",
       "    MeanTime/s       MAE      RMSE  Coverage  Diversity   Novelty  LOOCV_HR  \\\n",
       "0     0.109393  0.590087  0.646977  0.306962   0.344359  0.076681       NaN   \n",
       "1     1.360583  0.349836  0.391245  0.221848   0.438315  0.004450       NaN   \n",
       "2     6.064500  0.677091  0.679859  0.111914   0.179893  0.003070       NaN   \n",
       "3     0.668226  0.753723  0.803360  0.122867   0.454609  0.009551       NaN   \n",
       "4     0.016285  0.000000  0.000000  1.000000   0.000531  0.543995       NaN   \n",
       "5     0.110449  0.564364  0.671683  0.280952   0.343810  0.071127       0.0   \n",
       "6     1.375185  0.365606  0.399532  0.216019   0.385336  0.007110       0.0   \n",
       "7     6.321734  0.404854  0.404854  0.147590   0.141935  0.001882       0.0   \n",
       "8     0.682558  1.038975  1.085616  0.150381   0.355712  0.007172       0.0   \n",
       "9     0.015949  0.000000  0.000000  1.000000   0.000485  0.490019       0.0   \n",
       "10    0.122551  1.851563  2.132115  0.301229   0.355657  0.080890       NaN   \n",
       "11    1.365549  0.840567  0.908513  0.237981   0.368817  0.004180       NaN   \n",
       "12    6.229356  1.581315  1.609300  0.143343   0.153480  0.007868       NaN   \n",
       "13    0.681126  1.369214  1.432026  0.142790   0.400323  0.005965       NaN   \n",
       "14    0.109245  0.605490  0.760722  0.314838   0.345629  0.075653       NaN   \n",
       "15    1.371076  0.598623  0.625537  0.217667   0.463848  0.005815       NaN   \n",
       "16    6.227204  0.176121  0.176121  0.136952   0.167021  0.002170       NaN   \n",
       "17    0.672256  0.680657  0.701166  0.122762   0.437059  0.005694       NaN   \n",
       "18    0.107519  0.696024  0.762412  0.310981   0.347479  0.082290       NaN   \n",
       "19    1.355701  0.740127  0.772587  0.218229   0.429984  0.005673       NaN   \n",
       "\n",
       "    Validation_HR  Cumulative_HR  MeanReciprocal_HR  \\\n",
       "0            0.21           0.21              0.175   \n",
       "1            0.17           0.17              0.120   \n",
       "2            0.10           0.10              0.075   \n",
       "3            0.26           0.22              0.225   \n",
       "4            0.00           0.00              0.000   \n",
       "5             NaN           0.22              0.170   \n",
       "6             NaN           0.15              0.120   \n",
       "7             NaN           0.09              0.070   \n",
       "8             NaN           0.23              0.175   \n",
       "9             NaN           0.00              0.000   \n",
       "10           0.28           0.09              0.190   \n",
       "11           0.13           0.03              0.100   \n",
       "12           0.10           0.05              0.080   \n",
       "13           0.18           0.11              0.160   \n",
       "14           0.23           0.23              0.180   \n",
       "15           0.22           0.22              0.165   \n",
       "16           0.05           0.05              0.040   \n",
       "17           0.21           0.21              0.170   \n",
       "18           0.25           0.17              0.200   \n",
       "19           0.16           0.03              0.125   \n",
       "\n",
       "                                      ActualRating_HR  \n",
       "0   {2.0: 0.000819672131147541, 3.0: 0.00880455407...  \n",
       "1   {3.5: 0.0029213955443463642, 4.0: 0.0075286138...  \n",
       "2   {3.0: 0.0032903643050143315, 4.0: 0.0010526315...  \n",
       "3   {1.5: 0.0006134969325153375, 2.0: 0.0021276595...  \n",
       "4                                                  {}  \n",
       "5   {2.0: 0.002173913043478261, 3.0: 0.00653517759...  \n",
       "6   {3.0: 0.002000788488074118, 3.5: 0.00112359550...  \n",
       "7   {3.0: 0.00196078431372549, 4.0: 0.004290932799...  \n",
       "8   {1.0: 0.0011627906976744186, 1.5: 0.0029171766...  \n",
       "9                                                  {}  \n",
       "10  {1.0: 0.004166666666666667, 2.5: 0.00161290322...  \n",
       "11  {3.0: 0.0017543859649122805, 3.5: 0.0037543859...  \n",
       "12  {2.0: 0.0027777777777777775, 3.5: 0.0038712686...  \n",
       "13  {1.0: 0.0014705882352941176, 2.5: 0.0007462686...  \n",
       "14  {2.0: 0.0007518796992481202, 2.5: 0.0023809523...  \n",
       "15  {2.5: 0.0013157894736842105, 3.0: 0.0023529411...  \n",
       "16  {2.5: 0.002173913043478261, 3.5: 0.00227272727...  \n",
       "17  {2.0: 0.0030638297872340424, 3.0: 0.0006451612...  \n",
       "18  {3.0: 0.007597063967160636, 3.5: 0.00997442972...  \n",
       "19  {0.5: 0.0004098360655737705, 2.5: 0.0004098360...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.readCSV(filename).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and the Metrics class\n",
    "\n",
    "The recommendations for each userID are passed to the an instantiate object of the Metrics class for evaluation. It runs various tests and saves the results to a csv file for later analysis. It requires a few parameters upon initialisation to run the tests: \n",
    "- Top-N: the top number of recommendations to consider (used by all metrics bar coverage)\n",
    "- moviesPerPage: the number of movies that will appear per page for the end-user, used only by the meanReciprocalHR metric)\n",
    "- thresholdRating: the minimum rating to be considered by the cumulativeHR metric\n",
    "\n",
    "Below is a full list and description of the metrics used for testing.\n",
    "\n",
    "#### MAE\n",
    "\n",
    "Error on the predicted ratings from actual ratings. Calculated by taking the absolute difference between the predicted and actual ratings for every hit and finding the mean of these errors. Can range from 0 to infinite. Lower values show a more accurate set of rating predictions.\n",
    "\n",
    "#### RMSE\n",
    "\n",
    "Error on the predicted ratings from actual ratings. RMSE gives a higher weight to larger errors and an indication of the increase in variance of the frequency distribution of error magnitudes. Due to this, it will always be equal to or greater than MAE.\n",
    "\n",
    "RMSE is found by squaring the difference between predicted and actual ratings for hits, finding the mean of these and finally square rooting. Can range from 0 to infinite. Lower values show a more accurate set of rating predictions, with values similar to the MAE value showing less variation of the distribution of errors.\n",
    "\n",
    "#### Coverage\n",
    "\n",
    "The number of total movies from the data set the algorithm is able to recommend to the user. Ignores Top-N, dividing the total number of movies in the results by the movies available in the training set. Expressed as a percentage in decimal form ranging from 0 to 1.\n",
    "\n",
    "Higher coverage values are preferred to ensure the algorithm is accessing the full extent of the items available.\n",
    "\n",
    "#### Diversity\n",
    "\n",
    "How diverse the Top-N recommendations are i.e., are the Top-N movies very closely related (low diversity) or not (high diversity). Found finding the mean of the similarities of the Top-N movies (S) and subtracting from 1 (1-S). Expressed as a percentage in decimal form ranging from 0 to 1.\n",
    "\n",
    "Very diverse recommendations are more likely to engage the user. Less diverse recommendations may just be recommending very closely related movies, like sequels of movies that the user is most likely to have already seen.\n",
    "\n",
    "#### Novelty\n",
    "\n",
    "How novel the Top-N movies are i.e., how much of the long-tail of less popular movies is the algorithm able to recommend in the Top-N. Found by dividing the mean of the ranks of the Top-N movies by the lowest ranked movie in the training set. Expressed as a percentage in decimal form ranging from 0 to 1. \n",
    "\n",
    "Higher values are usually preferred however, very high values may cause a lack of trust in the recommendations from the user and cause them to disengage with the recommendation list.\n",
    "\n",
    "#### Validation HitRate\n",
    "\n",
    "How many movies from the Top-N recommendations are in the validation set. Simply the number of the movies from the Top-N in the validation set divided by the number of Top-N movies. Expressed as a percentage in decimal form ranging from 0 to 1. Higher values show more hits per user.\n",
    "\n",
    "#### LeaveOneOut-CrossValidation HitRate\n",
    "\n",
    "The number of times the algorithm recommends the movie left out for LOO-CV in the Top-N recommendations. Either 0 or 1 for every user. Higher values show more hits per user.\n",
    "\n",
    "Difficult to achieve as the algorithm could recommend many movies the user likes, but miss the one movie left out for this validation set. Useful for smaller data sets where training and test data is limited.\n",
    "\n",
    "#### Cumulative HitRate\n",
    "\n",
    "Exactly the same as validation hit-rate however, we now limit the hits to only hits with a predicted rating above some threshold rating. This is to avoid giving the algorithm a positive result even if its recommendations are movies it thinks the user won't actually like.\n",
    "\n",
    "#### Mean Reciprocal HitRate\n",
    "\n",
    "Weights the Top-N hits by which page they appear on for a paginated recommendation system. Works just like the validation hit-rate, but now splits up hits into groups of ranks, dividing by the group number (or page) it is in. It then sums these together to give the hit-rate. Higher values show more weighted hits per user.\n",
    "\n",
    "This is useful for system like Netflix where 5 movies are shown to a page. Our algorithm shouldn't be rewarded as highly for only recommending movies the user actually wants to watch on the last page where the user may not even see them.\n",
    "\n",
    "#### Actual Rating HitRate\n",
    "\n",
    "A breakdown of the hits per predicted rating given. The distribution shows us whether the algorithm tends to recommend movies it thinks the user will rate highly or not. The values can be normalised for the total movies available for each user in the validation set showing how many of the ratio for each rating it is able to correctly recommend.\n",
    "\n",
    "A mean value can be extracted from these to show which ratings the average rating given to the hits of the Top-N recommendations. Higher values will therefore be preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "- Basic results\n",
    "- Testing the rating prediction paramater\n",
    "- Testing the 'neighbours' parameter\n",
    "- Testing the threshold rating parameter\n",
    "- Testing the 'sample' parameter for item-based algorithms\n",
    "- Testing the 'sample' parameter for user-based algorithms\n",
    "- Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Parameters and setting up the tests\n",
    "\n",
    "The recommendation system assumes a 'Netflix' style end-user use case where 30 movies are shown to the user in a paginated form of 5 movies per page. We also only want to recommend movies to the user that have a predicted rating of 3.0 or more. As such, the metrics object for testing was instantiated with the parameters, topN=30, moviesPerPage=5, and thresholdRating=3.0.\n",
    "\n",
    "The algorithms have the following parameters which can be adjusted to affect the quality of movies recommended:\n",
    "- 'predict': rating prediction algorithm to use. This can be either of the following:\n",
    "    - 'calc': use the formulaically calculated value which takes the sum of the weighted similarities, divided by the sum of the unweighted similarities, introduces the input user's bias, and limits to a max rating of 5.0. More information on how this works can be found in part 1.\n",
    "    - 'mean': use the mean values from the train data,\n",
    "    - 'sims': multiply similarity scores by max possible rating for predicted ratings,\n",
    "    - 'norm_sims': normalise similarity scores then multiply by max possible rating for predicted ratings,\n",
    "    - 'rand': randomly generate ratings.\n",
    "\n",
    "- 'neighbours': the number of most similar neighbours to draw similarities from. This works slightly differently for item- or user-based algorithms. \n",
    "    - Item-based: the algorithm will sample the most similar items per item the input user has rated i.e., if neighbours=100, the algorithm samples the top 100 most similar movies to each movie the input user has rated.\n",
    "    - User-based: the number of most similar users to the input user. \n",
    "- 'threshold': the minimum rating from the input user's ratings which will be considered by the algorithm. The algorithm will remove any movies from the input user's ratings below this value.\n",
    "- 'sample': this parameter has a different use-case depending on whether the algorithm is item- or user-based.\n",
    "    - Item-based: samples the top-rated movies from the input user\n",
    "    - User-based: sample the most similar items per item each similar user has rated. Works similarly to the 'neighbours' parameter for item-based algorithms.\n",
    "    \n",
    "We will test each of the following parameters separately, controlling the dependant parameters with the following values: 'predict'='calc', 'threshold'=2.0, 'neighbours'=100, 'sample'=100.\n",
    "\n",
    "A control test of random predictions will also be run as a control which works by generating random similarity scores, independently generated random ratings, and returning the 30 movies with the highest similarity scores.\n",
    "\n",
    "A complete set of raw data can be found in *output/ML_MetricsRaw.csv*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the quality of various rating prediction methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four metrics consider the quality of rating predictions: MAE, RMSE, Cumulative HitRate and Actual Rating HitRate. From the data generated, rating predictions seemingly have negligible impact on runtimes so we will not consider those here.\n",
    "\n",
    "First, let's consider the MAE and RMSE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll look at the percentage differences between the Validation HitRates (i.e. the total hits not considering ratings) and the Cumulative HitRate. This will tell us the difference between the movies predicted that the user has watched and which of those movies the ratings prediction algorithm thinks the user will actually like. For the rating predictions to be working perfectly we would expect to see no difference between Validation HR and Cumulative HR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limiting the most similar neighbours considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum number of neighbours varies for item- and user-based algorithms as being the maximum number of movies and users in the train data respectively. In this case, those values are 10500 movies and 2822 users. Due to computational limitations causing slower runtimes though, we will be considering neighbours up to 200 for every algorithm apart from Item-Based KNN, where slower runtimes mean we can only test up to 100. However, we will see from the results that the largest variance in the data occurs at these lower values, with results beginning to converge at the upper bounds of our test range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the input user's ratings to some threshold rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each algorithm, the threshold rating parameter was tested from 0.5 up to 5.0 in increments of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the top rated movies for item-based algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum value for the sample parameter will be the value set for the maximum user ratings when initially limiting our data set for building the ratings pivot table, in this case 6000. Once again, computational limitations mean we shall only be testing up to 2000 for all algorithms, and up to 200 for the Item-Based KNN algorithm due to its slower runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling each similar user's most similar movies for user-based algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-running the algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discussion\n",
    "- ReRun basic test for LOO-CV at end.\n",
    "- Talk about bleeding edge algorithms in conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
